# -*- coding: utf-8 -*-
"""Beta_MMM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14klC7g67_QAaPRaWFD-MODrI2GzTqHA8
"""

import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import ElasticNet, Lasso, Ridge
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from scipy.optimize import minimize
from statsmodels.tsa.seasonal import seasonal_decompose
import io

from IPython.display import display, HTML, clear_output
import ipywidgets as widgets
from ipywidgets import interact, Dropdown, Text, Checkbox, IntText, FloatText, VBox, HBox, Button, Output, SelectMultiple, FileUpload

import matplotlib.pyplot as plt
import seaborn as sns

# --- Helper Functions (Keep helper functions in the first cell) ---

def format_number(x):
    if pd.isna(x): return ""
    if isinstance(x, (int, float, np.number)):
        if abs(x) >= 1e9: return f'{x/1e9:.2f}B'
        elif abs(x) >= 1e6: return f'{x/1e6:.2f}M'
        elif abs(x) >= 1e3: return f'{x/1e3:.2f}K'
        else: return f'{x:.2f}'
    return str(x)

def convert_indian_number(value):
    if isinstance(value, str):
        cleaned_value = value.replace(',', '').strip()
        if cleaned_value in ['-', ''] or cleaned_value.isspace(): return np.nan
        try: return float(cleaned_value)
        except ValueError: return np.nan
    if isinstance(value, (int, float, np.number)): return value
    return np.nan

def load_and_preprocess_data(uploaded_file):
    if not uploaded_file:
        print("No file uploaded.")
        return None

    file_name = list(uploaded_file.keys())[0]
    content = uploaded_file[file_name]['content']

    if file_name.endswith('.csv'):
        data = pd.read_csv(io.BytesIO(content))
    elif file_name.endswith(('.xlsx', '.xls')):
        data = pd.read_excel(io.BytesIO(content))
    else:
        raise ValueError("Unsupported file format. Please upload a CSV or Excel file.")

    if 'Week_Ending' not in data.columns:
        raise ValueError("The uploaded file must contain a 'Week_Ending' column.")

    try:
        data['Week_Ending'] = pd.to_datetime(data['Week_Ending'])
    except:
        try:
            data['Week_Ending'] = pd.to_datetime(data['Week_Ending'], format='%d-%m-%Y %H:%M')
        except:
            try:
                data['Week_Ending'] = pd.to_datetime(data['Week_Ending'], format='%m/%d/%Y')
            except:
                raise ValueError("Could not parse 'Week_Ending' column. Please ensure it's in a recognizable date format.")

    object_cols = data.select_dtypes(include=['object']).columns
    for col in object_cols:
        if col != 'Week_Ending':
            data[col] = data[col].apply(convert_indian_number)
            data[col] = pd.to_numeric(data[col], errors='coerce')

    # Store original data before any potential FE
    globals()['original_data'] = data.copy()

    return data

def get_transformation_recommendations(numeric_df):
    numeric_df = numeric_df.select_dtypes(include=[np.number])
    if numeric_df.empty: return pd.DataFrame(columns=['Variable', 'Skewness', 'Kurtosis', 'Recommendation', 'Color'])

    skewness = numeric_df.skew()
    kurtosis = numeric_df.kurtosis()

    recommendations = []
    for col in numeric_df.columns:
        skew_val = skewness[col]
        kurt_val = kurtosis[col]

        if abs(skew_val) > 1.5:
            recommendation = "Log transformation (high right skew)" if skew_val > 1.5 else "Square root or Box-Cox transformation (high left skew)"
            color = "#ffcccc" # Lighter red
        elif abs(skew_val) > 0.75:
            recommendation = "Consider mild transformation (moderate skew)"
            color = "#ffebcc" # Lighter orange
        else:
            recommendation = "No transformation needed (approximately symmetric)"
            color = "#ccffcc" # Lighter green

        if abs(kurt_val) > 3:
            recommendation += " | Potential outliers detected (high kurtosis)"
            if color == "#ccffcc": # If not already red or orange, make it light orange
                 color = "#ffebcc"


        recommendations.append({
            'Variable': col, 'Skewness': skew_val, 'Kurtosis': kurt_val,
            'Recommendation': recommendation, 'Color': color
        })

    return pd.DataFrame(recommendations)


def perform_comprehensive_eda(data, target_var='Sales'):
    print("="*60)
    print("COMPREHENSIVE EXPLORATORY DATA ANALYSIS")
    print("="*60)

    print("\n1. BASIC DATASET INFORMATION")
    print("="*40)
    print(f"Shape: {data.shape}")
    print(f"Columns: {list(data.columns)}")
    if 'Week_Ending' in data.columns:
        print(f"Date Range: {data['Week_Ending'].min()} to {data['Week_Ending'].max()}")
    print(f"Total Missing Values: {data.isnull().sum().sum()}")

    print("\n\n1.1 MISSING VALUES")
    print("="*40)
    missing_values = data.isnull().sum()
    missing_values = missing_values[missing_values > 0].sort_values(ascending=False)
    if missing_values.empty:
        print("No missing values found in the dataset.")
    else:
        missing_values_df = missing_values.to_frame(name='Missing Count')
        missing_values_df['Missing Percentage (%)'] = (missing_values_df['Missing Count'] / len(data)) * 100
        print("Missing values per column:")
        # Format the percentage column
        missing_values_df['Missing Percentage (%)'] = missing_values_df['Missing Percentage (%)'].map('{:.2f}%'.format)
        display(missing_values_df)

    numeric_df = data.select_dtypes(include=[np.number])

    print("\n\n2. SUMMARY STATISTICS")
    print("="*40)

    formatted_stats = numeric_df.describe().copy()
    display(formatted_stats)


    transformation_df = get_transformation_recommendations(numeric_df)
    print("\nTransformation Recommendations:")

    html = '<table border="1" class="dataframe">'
    html += '<thead><tr style="text-align: right;">'
    for col in transformation_df.columns:
        if col != 'Color': html += f'<th>{col}</th>'
    html += '</tr></thead><tbody>'

    for _, row in transformation_df.iterrows():
        html += f'<tr style="background-color: {row["Color"]};">'
        for col in transformation_df.columns:
            if col != 'Color':
                value = row[col]
                # Format numeric columns to 4 decimal places
                if isinstance(value, (int, float, np.number)):
                    html += f'<td>{value:.4f}</td>'
                else:
                    html += f'<td>{value}</td>'
        html += '</tr>'

    html += '</tbody></table>'
    display(HTML(html))

    print("\n\n3. UNIVARIATE ANALYSIS")
    print("="*40)

    for col in numeric_df.columns:
        if not pd.api.types.is_numeric_dtype(data[col]): continue

        mean_val = data[col].mean()
        median_val = data[col].median()

        plt.figure(figsize=(10, 6))
        sns.histplot(data[col], kde=True)
        plt.title(f"Distribution of {col}")
        plt.xlabel(col)
        plt.ylabel("Frequency")

        # Format x-axis tick labels
        if data[col].max() > 1000: # Apply formatting only for larger numbers
            plt.gca().get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, _: format_number(x)))

        plt.axvline(mean_val, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {format_number(mean_val)}')
        plt.axvline(median_val, color='green', linestyle='dashed', linewidth=1, label=f'Median: {format_number(median_val)}')

        plt.legend()
        plt.show()

    print("\n\n4. BIVARIATE ANALYSIS: RELATIONSHIP WITH TARGET VARIABLE")
    print("="*40)

    if target_var in numeric_df.columns:
        numeric_cols_for_scatter = [col for col in numeric_df.columns if col != target_var]

        for col in numeric_cols_for_scatter:
            if not pd.api.types.is_numeric_dtype(data[col]) or not pd.api.types.is_numeric_dtype(data[target_var]): continue

            correlation = data[col].corr(data[target_var])

            plt.figure(figsize=(10, 6))
            plt.scatter(data[col], data[target_var])
            plt.title(f"{target_var} vs {col} (r = {correlation:.3f})")
            plt.xlabel(col)
            plt.ylabel(target_var)
            plt.grid(True)

            # Format axes labels
            if data[col].max() > 1000:
                 plt.gca().get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, _: format_number(x)))
            if data[target_var].max() > 1000:
                 plt.gca().get_yaxis().set_major_formatter(plt.FuncFormatter(lambda y, _: format_number(y)))

            plt.show()

    print("\n\n5. TIME SERIES ANALYSIS")
    print("="*40)

    if 'Week_Ending' in data.columns and target_var in data.columns:
        if pd.api.types.is_numeric_dtype(data[target_var]):
            plt.figure(figsize=(12, 6))
            plt.plot(data['Week_Ending'], data[target_var])
            plt.title(f"{target_var} Over Time")
            plt.xlabel("Week Ending")
            plt.ylabel(target_var)
            plt.grid(True)
            # Format y-axis labels
            if data[target_var].max() > 1000:
                 plt.gca().get_yaxis().set_major_formatter(plt.FuncFormatter(lambda y, _: format_number(y)))
            plt.show()

            print("Seasonal Decomposition:")
            try:
                temp_df = data.set_index('Week_Ending').sort_index()
                if len(temp_df) >= 2 * 52:
                    decomposition = seasonal_decompose(temp_df[target_var], period=52, model='multiplicative', extrapolate_trend='freq')
                    fig, axes = plt.subplots(4, 1, figsize=(12, 10))
                    axes[0].plot(decomposition.observed)
                    axes[0].set_ylabel("Observed")
                    axes[1].plot(decomposition.trend)
                    axes[1].set_ylabel("Trend")
                    axes[2].plot(decomposition.seasonal)
                    axes[2].set_ylabel("Seasonal")
                    axes[3].plot(decomposition.resid)
                    axes[3].set_ylabel("Residual")
                    fig.suptitle("Seasonal Decomposition (Period 52)", y=0.98)

                    # Format y-axis labels for decomposition plots if values are large
                    for ax in axes:
                         if ax.get_ylim()[1] > 1000:
                              ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda y, _: format_number(y)))

                    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
                    plt.show()

                else:
                    print(f"Not enough data points ({len(temp_df)}) to perform seasonal decomposition with period 52. Need at least {2*52}.")
            except Exception as e: print(f"Could not perform seasonal decomposition: {str(e)}")

    print("\n\n6. CORRELATION ANALYSIS")
    print("="*40)

    numeric_df_for_corr = data.select_dtypes(include=[np.number])
    if not numeric_df_for_corr.empty:
        corr = numeric_df_for_corr.corr()
        # The correlations variable was calculated here and is now global
        globals()['correlations'] = corr.copy() # Make it explicitly global here

        plt.figure(figsize=(12, 10))
        sns.heatmap(corr, annot=True, fmt=".2f", cmap='coolwarm')
        plt.title("Correlation Matrix - All Variables")
        plt.show()

        media_keywords = ['impressions', 'clicks', 'social', 'search', 'email', 'video']
        media_cols = [col for col in numeric_df_for_corr.columns if any(keyword in col.lower() for keyword in media_keywords)]

        if media_cols and target_var in numeric_df_for_corr.columns:
            media_corr = numeric_df_for_corr[media_cols + [target_var]].corr()
            target_corr = media_corr[target_var].drop(target_var).sort_values(ascending=False)
            plt.figure(figsize=(10, 6))
            sns.barplot(x=target_corr.index, y=target_corr.values, palette='viridis')
            plt.title(f"Correlation of Media Variables with {target_var}")
            plt.xlabel("Media Variables")
            plt.ylabel("Correlation Coefficient")
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            plt.show()
            # Display correlation values with 3 decimal places
            print(target_corr.round(3).to_frame("Correlation"))

            print("\n\n6.1 MEDIA EXECUTION SHARE")
            print("="*40)
            media_totals = numeric_df_for_corr[media_cols].sum()
            total_media = media_totals.sum()
            if total_media > 0:
                media_share = (media_totals / total_media) * 100
                media_share = media_share.sort_values(ascending=False)
                plt.figure(figsize=(10, 6))
                sns.barplot(x=media_share.index, y=media_share.values, palette='magma')
                plt.title("Media Execution Share by Channel")
                plt.xlabel("Channel")
                plt.ylabel("Share (%)")
                plt.xticks(rotation=45, ha='right')
                plt.tight_layout()
                plt.show()

                print("Media Execution Share Percentage:")
                # Display media share percentage with 2 decimal places and % sign
                display(media_share.round(2).to_frame("Share (%)").style.format({'Share (%)': '{:.2f}%'}))

    print("\n\n7. OUTLIER ANALYSIS")
    print("="*40)

    if target_var in numeric_df.columns and pd.api.types.is_numeric_dtype(data[target_var]):
        Q1 = data[target_var].quantile(0.25)
        Q3 = data[target_var].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = data[(data[target_var] < lower_bound) | (data[target_var] > upper_bound)]
        normal_data = data[~((data[target_var] < lower_bound) | (data[target_var] > upper_bound))].copy()
        print(f"Number of potential outliers in {target_var}: {len(outliers)}")

        if len(outliers) > 0:
            print("Outlier values:")
            display(outliers[['Week_Ending', target_var]])
            plt.figure(figsize=(12, 6))
            plt.plot(normal_data['Week_Ending'], normal_data[target_var], marker='o', linestyle='-', markersize=5, label='Normal Values')
            plt.plot(outliers['Week_Ending'], outliers[target_var], marker='o', linestyle='', color='red', markersize=10, label='Outliers')
            plt.axhline(y=upper_bound, color='red', linestyle='dashed', label=f'Upper Bound: {format_number(upper_bound)}')
            plt.axhline(y=lower_bound, color='red', linestyle='dashed', label=f'Lower Bound: {format_number(lower_bound)}')
            plt.title(f"Outlier Detection in {target_var}")
            plt.xlabel("Date")
            plt.ylabel(target_var)
            plt.legend()
            plt.grid(True)
            # Format y-axis labels
            if data[target_var].max() > 1000:
                 plt.gca().get_yaxis().set_major_formatter(plt.FuncFormatter(lambda y, _: format_number(y)))
            plt.show()

    print("\nEDA Complete.")
    print("="*60)
    # The correlations variable was calculated in the EDA step and is now global
    # returning data and numeric_df is sufficient
    return data.copy(), numeric_df.copy() # Removed correlations from return as it's global

def bucket_variables(data):
    """
    Placeholder function for bucketing variables.
    Replace this with your actual logic to categorize variables
    into dependent, base, media, promo, and other independent variables.

    Args:
        data (pd.DataFrame): The input DataFrame.

    Returns:
        tuple: A tuple containing:
            - dependent_var (str): The name of the dependent variable.
            - base_vars (list): List of base variable names.
            - media_vars (list): List of media variable names.
            - promo_vars (list): List of promo variable names.
            - other_vars (list): List of other independent variable names.
            - independent_vars (list): List of all independent variable names.
    """
    # Removed the "Placeholder: bucket_variables function called" print statement
    # print("\n--- Placeholder: bucket_variables function called ---")
    # print("Please replace this placeholder with your actual variable bucketing logic.")

    target_var = 'Sales'
    all_cols = data.columns.tolist()
    independent_vars = [col for col in all_cols if col != target_var and col != 'Week_Ending']

    media_keywords = ['impressions', 'clicks', 'social', 'search', 'email', 'video', 'spend', 'cost', 'budget'] # Add spend/cost/budget keywords
    promo_keywords = ['discount', 'promo'] # Add promo keyword
    base_keywords = ['price', 'macro'] # Base keywords

    base_vars = [col for col in independent_vars if any(keyword in col.lower() for keyword in base_keywords)]
    media_vars = [col for col in independent_vars if any(keyword in col.lower() for keyword in media_keywords)]
    promo_vars = [col for col in independent_vars if any(keyword in col.lower() for keyword in promo_keywords)]
    other_vars = [col for col in independent_vars if col not in base_vars + media_vars + promo_vars]

    # Removed the placeholder print statements for variable lists
    # print(f"Placeholder dependent_var: {target_var}") # Use target_var directly
    # print(f"Placeholder base_vars: {base_vars}")
    # print(f"Placeholder media_vars: {media_vars}")
    # print(f"Placeholder promo_vars: {promo_vars}")
    # print(f"Placeholder other_vars: {other_vars}")
    # print(f"Placeholder independent_vars: {independent_vars}")


    return target_var, base_vars, media_vars, promo_vars, other_vars, independent_vars # Return target_var

def prepare_data_for_modeling_and_bucket(data):
    print("\n" + "="*60)
    print("DATA PREPARATION FOR MODELING (INITIAL BUCKEING)")
    print("="*60)

    target_var = 'Sales'
    dependent_var, current_base_vars, current_media_vars, current_promo_vars, current_other_vars, current_independent_vars = bucket_variables(data)

    # Removed the detailed print statements for initial bucketing
    # print("\n--- Initial Variable Bucketing for Modeling (Before Adstock/Saturation) ---")
    # print("Dependent Variable:", dependent_var)
    # print("Independent Variables:")
    #
    # print("  Base & Non-Marketing:", current_base_vars)
    # print("  Media (Original):", current_media_vars)
    # print("  Promotions:", current_promo_vars)
    # if current_other_vars: print("  Other Variables (not explicitly categorized):", current_other_vars)

    print("-" * 30)
    print("--- Variables for Modeling (Tabular - Initial Bucketing) ---")
    variable_list_data = []

    if dependent_var in data.columns: variable_list_data.append({'Category': 'Dependent Variable', 'Variable Name': dependent_var})

    for var in current_base_vars: variable_list_data.append({'Category': 'Independent Variables (Base & Non-Marketing)', 'Variable Name': var})
    for var in current_media_vars: variable_list_data.append({'Category': 'Independent Variables (Media - Original)', 'Variable Name': var})
    for var in current_promo_vars: variable_list_data.append({'Category': 'Independent Variables (Promo)', 'Variable Name': var})
    if current_other_vars:
        for var in current_other_vars:
             variable_list_data.append({'Category': 'Independent Variables (Other)', 'Variable Name': var})

    variable_list_df = pd.DataFrame(variable_list_data)
    display(variable_list_df)
    print("-" * 30)

    print("\nInitial Data Preparation for Modeling Complete.")
    print("="*60)

    return data.copy(), current_base_vars, current_media_vars, current_promo_vars, current_other_vars, current_independent_vars

def color_code_yoy_change(value):
    if isinstance(value, (int, float)):
        if value > 0:
            return 'background-color: lightgreen'
        elif value < 0:
            return 'background-color: salmon'
    return ''

def create_media_execution_report(data, fy_ranges):
    print("\n" + "="*60)
    print("GENERATING MEDIA EXECUTION REPORT")
    print("="*60)

    if 'Week_Ending' not in data.columns:
        print("Warning: 'Week_Ending' column not found. Cannot generate media execution report.")
        return pd.DataFrame()

    data['Week_Ending'] = pd.to_datetime(data['Week_Ending'])

    media_keywords = ['impressions', 'clicks', 'social', 'search', 'email', 'video', 'spend', 'cost', 'budget']
    engineered_media_keywords = ['_pre_', '_post_', 'super_campaign']
    all_potential_media_cols = [col for col in data.columns if any(keyword in col.lower() for keyword in media_keywords + engineered_media_keywords)]

    media_cols = [col for col in all_potential_media_cols if pd.api.types.is_numeric_dtype(data[col])]

    if not media_cols:
        print("No numeric media-related columns found (e.g., 'Impressions', 'Clicks', 'Spend'). Cannot generate report.")
        return pd.DataFrame()

    report_data = []

    fy_totals = {}
    for fy, dates in fy_ranges.items():
        start_date = pd.to_datetime(dates[0])
        end_date = pd.to_datetime(dates[1])
        fy_data = data[(data['Week_Ending'] >= start_date) & (data['Week_Ending'] <= end_date)]
        fy_totals[fy] = fy_data[media_cols].sum()

    fy_years = sorted(fy_ranges.keys())
    yoy_changes = {}
    for i in range(1, len(fy_years)):
        current_fy = fy_years[i]
        previous_fy = fy_years[i-1]
        yoy_col_name = f'{current_fy} YoY Execution Change (%)'
        # Handle division by zero in previous year's total execution
        yoy_changes[yoy_col_name] = ((fy_totals[current_fy] - fy_totals[previous_fy]) / fy_totals[previous_fy].replace(0, np.nan)) * 100
        yoy_changes[yoy_col_name] = yoy_changes[yoy_col_name].replace([np.inf, -np.inf], np.nan).fillna(0)


    for media_var in media_cols:
        row_data = {'Media Channel': media_var}
        for fy in fy_years:
            row_data[f'{fy} Total Execution'] = fy_totals[fy].get(media_var, 0)
        for yoy_col_name, changes in yoy_changes.items():
             row_data[yoy_col_name] = changes.get(media_var, 0)
        report_data.append(row_data)

    report_df = pd.DataFrame(report_data)

    for col in report_df.columns:
        if 'Total Execution' in col:
            report_df[col] = report_df[col].apply(format_number)
        elif 'YoY Execution Change (%)' in col:
            report_df[col] = report_df[col].apply(lambda x: f'{x:.1f}%' if pd.notna(x) else '')

    print("Media Execution Report Generated.")
    return report_df


def run_analysis_and_eda(uploaded_file):
    global data
    if not uploaded_file:
        print("No file uploaded. Please upload a file to continue.")
        return

    try:
        # Clear any previous data stored globally before a new run
        if 'data' in globals(): del globals()['data']
        if 'original_data' in globals(): del globals()['original_data']
        if 'initial_base_vars' in globals(): del globals()['initial_base_vars']
        if 'initial_media_vars' in globals(): del globals()['initial_media_vars']
        if 'initial_promo_vars' in globals(): del globals()['initial_promo_vars']
        if 'initial_other_vars' in globals(): del globals()['initial_other_vars']
        if 'correlations' in globals(): del globals()['correlations']


        data = load_and_preprocess_data(uploaded_file)
        if data is None: return # Exit if no file uploaded

        target_var = 'Sales'
        globals()['target_var'] = target_var # Make target_var global

        print("--- Data Loading and Preprocessing Complete ---")
        print(f"Data shape: {data.shape}")
        print(f"Columns: {list(data.columns)}")
        print("-" * 30)

        # Perform EDA
        data, numeric_df = perform_comprehensive_eda(data, target_var=target_var)

        # Perform initial bucketing with original variables after EDA
        # This populates initial_base_vars, initial_promo_vars, initial_other_vars etc.
        # Note: This call also prints the initial bucketing table.
        data_for_initial_bucket = data.copy() # Use a copy so FE operates on the original
        data_for_initial_bucket, initial_base_vars, initial_media_vars, initial_promo_vars, initial_other_vars, initial_independent_vars = prepare_data_for_modeling_and_bucket(data_for_initial_bucket)

        globals()['initial_base_vars'] = initial_base_vars
        globals()['initial_promo_vars'] = initial_promo_vars
        globals()['initial_other_vars'] = initial_other_vars
        globals()['initial_media_vars'] = initial_media_vars # Store initial media vars globally
        globals()['initial_independent_vars'] = initial_independent_vars # Store initial independent vars globally


        print("\n--- Initial Data Preparation for Feature Engineering and Modeling Complete ---")
        print("Please proceed to the next cell for Feature Engineering options.")


    except Exception as e:
        print(f"An error occurred: {str(e)}")
        print("Please check your file format and try again.")

# --- Data Upload and EDA Section ---
print("# Data Upload and Exploratory Data Analysis")
print("Please upload your data file (CSV or Excel format):")

uploader = FileUpload(
    accept='.csv,.xlsx,.xls',
    multiple=False
)

run_eda_button = Button(description="Run EDA", button_style='success')
output_eda = Output()

def on_run_eda_button_clicked(b):
    with output_eda:
        output_eda.clear_output()
        run_analysis_and_eda(uploader.value)

run_eda_button.on_click(on_run_eda_button_clicked)

display(VBox([uploader, run_eda_button, output_eda]))

# # Feature Engineering

def generate_seasonality_index(data, date_col, period=52):
    if date_col not in data.columns:
        print(f"Date column '{date_col}' not found in data.")
        return data

    temp_df = data.copy().sort_values(date_col)
    if 'Sales' not in temp_df.columns or not pd.api.types.is_numeric_dtype(temp_df['Sales']):
        print(f"Warning: 'Sales' column is not numeric. Cannot generate seasonality index.")
        return data

    seasonality_col = f'seasonality_index_{period}'
    # Check if column already exists to avoid duplicates
    if seasonality_col in temp_df.columns:
         print(f"Column '{seasonality_col}' already exists. Skipping creation.")
         return data # Return original data if column exists

    temp_df[seasonality_col] = temp_df['Sales'].rolling(window=period, min_periods=1).mean()
    temp_df[seasonality_col] = temp_df.apply(lambda row: row['Sales'] / row[seasonality_col] if row[seasonality_col] != 0 and pd.notna(row['Sales']) else 1, axis=1)
    temp_df[seasonality_col] = temp_df[seasonality_col].fillna(1)

    print(f"Generated seasonality index with period {period}")
    return temp_df

def add_specific_date_dummies(data, date_col, specific_dates):
    if date_col not in data.columns:
        print(f"Date column '{date_col}' not found in data.")
        return data

    modified_data = data.copy() # Work on a copy

    for date_str in specific_dates:
        try:
            date_obj = datetime.strptime(date_str, '%Y-%m-%d')
            dummy_col = f'dummy_{date_str.replace("-", "_")}'
            # Check if column already exists
            if dummy_col in modified_data.columns:
                 print(f"Column '{dummy_col}' already exists. Skipping creation.")
                 continue # Skip this date if dummy already exists

            modified_data[dummy_col] = (modified_data[date_col] == date_obj).astype(int)
            print(f"Added dummy variable for {date_str}")
        except ValueError:
            print(f"Invalid date format: {date_str}. Use YYYY-MM-DD format.")

    return modified_data

def split_media_variable(data, date_col, media_var, split_date_str):
    if date_col not in data.columns or media_var not in data.columns:
        print(f"Date column '{date_col}' or media variable '{media_var}' not found in data.")
        return data, None, None, False

    modified_data = data.copy() # Work on a copy

    try:
        split_date = datetime.strptime(split_date_str, '%Y-%m-%d')
        pre_col = f"{media_var}_pre_{split_date.strftime('%Y_%m_%d')}"
        post_col = f"{media_var}_post_{split_date.strftime('%Y_%m_%d')}"

        # Check if split columns already exist
        if pre_col in modified_data.columns and post_col in modified_data.columns:
             print(f"Split columns '{pre_col}' and '{post_col}' already exist for '{media_var}' at '{split_date_str}'. Skipping creation.")
             return data, pre_col, post_col, False # Indicate not successful (already exists)


        if not pd.api.types.is_numeric_dtype(modified_data[media_var]):
            print(f"Warning: Media variable '{media_var}' is not numeric. Cannot split.")
            return data, None, None, False

        modified_data[pre_col] = modified_data.apply(lambda row: row[media_var] if row[date_col] < split_date else 0, axis=1)
        modified_data[post_col] = modified_data.apply(lambda row: row[media_var] if row[date_col] >= split_date else 0, axis=1)


        print(f"Split {media_var} into {pre_col} and {post_col} at {split_date_str}")
        return modified_data, pre_col, post_col, True

    except ValueError:
        print(f"Invalid date format: {split_date_str}. Use YYYY-MM-DD format.")
        return data, None, None, False

def create_super_campaign_variable(data, component_vars, super_campaign_name):
    missing_vars = [var for var in component_vars if var not in data.columns]
    if missing_vars:
        print(f"Component variables not found in data: {missing_vars}")
        return data, None, False

    modified_data = data.copy() # Work on a copy

    # Check if super campaign column already exists
    if super_campaign_name in modified_data.columns:
         print(f"Super campaign column '{super_campaign_name}' already exists. Skipping creation.")
         return data, super_campaign_name, False # Indicate not successful (already exists)

    non_numeric_components = [var for var in component_vars if not pd.api.types.is_numeric_dtype(modified_data[var])]
    if non_numeric_components:
        print(f"Warning: Non-numeric component variables found: {non_numeric_components}. Cannot create super campaign.")
        return data, None, False

    modified_data[super_campaign_name] = modified_data[component_vars].sum(axis=1)
    print(f"Created super campaign variable '{super_campaign_name}' from {component_vars}")
    return modified_data, super_campaign_name, True

def perform_feature_engineering():
    print("\n" + "="*60)
    print("FEATURE ENGINEERING")
    print("="*60)

    if 'data' not in globals() or data is None:
         print("No data available. Please run Data Upload and EDA first.")
         return

    # Use a non-local variable to hold the data and update it
    # Start with a copy of the current data state from the previous step
    fe_data = globals()['data'].copy()
    globals()['fe_data'] = fe_data # Make this accessible globally for modification by button clicks

    output_fe = widgets.Output()
    display(output_fe)

    # Identify potential media variables for splitting and super campaigns (using the current data state for selection)
    media_keywords = ['impressions', 'clicks', 'social', 'search', 'email', 'video', 'spend', 'cost', 'budget']
    potential_media_vars = [col for col in fe_data.columns if any(keyword in col.lower() for keyword in media_keywords) and pd.api.types.is_numeric_dtype(fe_data[col])]
    potential_media_vars.sort() # Sort alphabetically for consistent numbering

    # Define the FE widgets
    seasonality_text = widgets.Text(description='Periods (e.g., 52, 26):')
    dummy_dates_text = widgets.Text(description='Dates (YYYY-MM-DD):')
    media_var_split_text = widgets.Text(description='Select variable by number:')
    split_date_text = widgets.Text(description='Split Date (YYYY-MM-DD):')
    component_vars_text = widgets.Text(description='Select component variables by number (comma-separated):')
    super_campaign_name_text = widgets.Text(description='Super Campaign Name:')

    create_feature_button = widgets.Button(description='Create Features', button_style='primary')
    undo_fe_button = widgets.Button(description="Undo Feature Engineering", button_style='warning')

    seasonality_output = widgets.Output()
    dummy_dates_output = widgets.Output()
    split_variable_output = widgets.Output()
    super_campaign_output = widgets.Output()
    undo_fe_output = widgets.Output()

    # Group widgets into a VBox for initial display
    fe_widgets_vbox = VBox([
        widgets.HTML("<h3>Feature Engineering Options</h3>"),
        widgets.HTML("<h4>Seasonality Index Creation</h4>"),
        VBox([seasonality_text]), # Moved button logic to create_feature_button
        seasonality_output,
        widgets.HTML("<h4>Dummy Variable Creation</h4>"),
        VBox([dummy_dates_text]), # Moved button logic to create_feature_button
        dummy_dates_output,
        widgets.HTML("<h4>Variable Splitting</h4>"),
        VBox([media_var_split_text, split_date_text]), # Moved button logic to create_feature_button
        split_variable_output,
        widgets.HTML("<h4>Super Campaign Creation</h4>"),
        VBox([component_vars_text, super_campaign_name_text]), # Moved button logic to create_feature_button
        super_campaign_output,
        HBox([create_feature_button, undo_fe_button]), # Group buttons
        undo_fe_output,
    ])

    # Function to display FE widgets
    def display_fe_widgets():
         with output_fe:
             clear_output(wait=True) # Clear previous FE setup display
             display(fe_widgets_vbox)
             if potential_media_vars:
                  print("Available numeric media variables for splitting and super campaign creation:")
                  for i, var in enumerate(potential_media_vars):
                      print(f"{i+1}. {var}")
             else:
                 print("No numeric media variables found for splitting or super campaign creation.")


    # Initial display of FE widgets
    display_fe_widgets()

    # Handle Create Feature button click
    def on_create_feature_button_clicked(b):
         with seasonality_output, dummy_dates_output, split_variable_output, super_campaign_output:
             clear_output(wait=True) # Clear previous output within the specific output widgets
             nonlocal fe_data # Use nonlocal to modify fe_data

             # Process Seasonality
             seasonality_input = seasonality_text.value.strip()
             if seasonality_input:
                 try:
                     seasonality_periods = [int(p.strip()) for p in seasonality_input.split(',') if p.strip()]
                     if all(p > 0 for p in seasonality_periods):
                         for period in seasonality_periods:
                             fe_data = generate_seasonality_index(fe_data, 'Week_Ending', period=period)
                         print("-" * 30)
                     else:
                         print("All seasonality periods must be positive integers.")
                 except ValueError:
                     print("Invalid seasonality input. Please enter comma-separated integers.")

             # Process Dummy Dates
             dummy_dates_input = dummy_dates_text.value.strip()
             if dummy_dates_input:
                 specific_dates = [d.strip() for d in dummy_dates_input.split(',') if d.strip()]
                 valid_dates = []
                 invalid_dates = []
                 for date_str in specific_dates:
                      try:
                          datetime.strptime(date_str, '%Y-%m-%d')
                          valid_dates.append(date_str)
                      except ValueError:
                          invalid_dates.append(date_str)

                 if invalid_dates:
                      print(f"Invalid date format for: {invalid_dates}. Please use YYYY-MM-DD format.")
                 else:
                      fe_data = add_specific_date_dummies(fe_data, 'Week_Ending', valid_dates)
                      print("-" * 30)

             # Process Variable Splitting
             media_var_index_str = media_var_split_text.value.strip()
             split_date_str = split_date_text.value.strip()

             if media_var_index_str and split_date_str:
                 try:
                     media_var_index = int(media_var_index_str) - 1
                     if 0 <= media_var_index < len(potential_media_vars):
                         media_var_to_split = potential_media_vars[media_var_index]
                         fe_data, pre_col, post_col, success = split_media_variable(fe_data, 'Week_Ending', media_var_to_split, split_date_str)
                         if success:
                             print("-" * 30)
                     else:
                         print(f"Invalid number for variable splitting. Please enter a number between 1 and {len(potential_media_vars)}.")
                 except ValueError:
                     print("Invalid input for variable splitting. Please enter the number corresponding to the variable.")

             # Process Super Campaign Creation
             component_vars_indices_str = component_vars_text.value.strip()
             super_campaign_name = super_campaign_name_text.value.strip()

             if component_vars_indices_str and super_campaign_name:
                 try:
                     component_indices = [int(idx.strip()) - 1 for idx in component_vars_indices_str.split(',') if idx.strip()]
                     component_vars_selected = []
                     invalid_indices = []
                     for idx in component_indices:
                         if 0 <= idx < len(potential_media_vars):
                             component_vars_selected.append(potential_media_vars[idx])
                         else:
                             invalid_indices.append(idx + 1) # Add 1 back for display

                     if invalid_indices:
                         print(f"Invalid numbers for super campaign: {invalid_indices}. Please enter numbers between 1 and {len(potential_media_vars)}.")
                         return

                     if not component_vars_selected:
                          print("No valid component variables selected for super campaign.")
                          return

                     fe_data, super_campaign_col, success = create_super_campaign_variable(fe_data, component_vars_selected, super_campaign_name)
                     if success:
                         print("-" * 30)

                 except ValueError:
                     print("Invalid input for super campaign. Please enter comma-separated numbers corresponding to the variables.")

             # Update the global data variable with the modified fe_data
             globals()['data'] = fe_data.copy() # Update global data

             # Display features created
             print("\n--- Data Head After Feature Engineering ---")
             display(fe_data.head())
             print("\n--- Columns After Feature Engineering ---")
             print(list(fe_data.columns))
             print("-" * 30)
             print("Feature Engineering applied. You can apply more features or Undo.")


    create_feature_button.on_click(on_create_feature_button_clicked)


    # Handle Undo button click
    def on_undo_fe_button_clicked(b):
         with undo_fe_output:
             clear_output(wait=True) # Clear previous output within undo output widget
             nonlocal fe_data # Use nonlocal to modify fe_data
             if 'original_data' in globals() and globals()['original_data'] is not None:
                 fe_data = globals()['original_data'].copy()
                 globals()['data'] = fe_data.copy() # Update global data
                 print("\nFeature Engineering reverted. Data restored to state before Feature Engineering.")
                 print("\n--- Data Head After Undo (Original Data) ---") # Clarified title
                 display(fe_data.head())
                 print("\n--- Columns After Undo (Original Data) ---") # Clarified title
                 print(list(fe_data.columns))
                 print("-" * 30)
                 # After undo, do NOT redisplay the FE widgets setup. Just show the reverted data.
                 # display_fe_widgets() # Removed this line
             else:
                 print("Original data before Feature Engineering not found. Cannot undo.")


    undo_fe_button.on_click(on_undo_fe_button_clicked)


    print("\nFeature Engineering Setup Complete. Use the widgets above to perform feature engineering.")
    print("Click the 'Create Features' button to apply selected transformations.")
    print("Click 'Undo Feature Engineering' to revert changes made in this section.")
    print("="*60)

    # The actual feature engineering is triggered by the button clicks and updates the global 'data' variable.
    # No need to return fe_data here as it's handled globally by button callbacks.

# --- Feature Engineering Section ---
print("# Feature Engineering")
print("Configure and apply feature engineering transformations.")

run_fe_setup_button = Button(description="Setup Feature Engineering", button_style='info')
output_fe_setup = Output()

def on_run_fe_setup_button_clicked(b):
    with output_fe_setup:
        output_fe_setup.clear_output()
        perform_feature_engineering()

run_fe_setup_button.on_click(on_run_fe_setup_button_clicked)

display(VBox([run_fe_setup_button, output_fe_setup]))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display, HTML, clear_output
import ipywidgets as widgets
from ipywidgets import VBox, HBox, Button, Output, FileUpload, Dropdown, Text, SelectMultiple, FloatText, IntText

# Assuming apply_adstock and apply_saturation functions are defined elsewhere or will be added.
# Placeholder for apply_adstock function
def apply_adstock(data_series, decay_rate):
    """Applies geometric adstock transformation."""
    adstocked_series = data_series.copy()
    # Ensure data_series is numeric and handle potential NaNs before loop
    if not pd.api.types.is_numeric_dtype(adstocked_series):
        print(f"Warning: Data series '{data_series.name}' is not numeric. Cannot apply adstock.")
        return data_series # Return original or empty series as appropriate

    adstocked_series = adstocked_series.fillna(0) # Fill NaN with 0 for calculation

    for i in range(1, len(adstocked_series)):
        adstocked_series.iloc[i] = adstocked_series.iloc[i] + adstocked_series.iloc[i-1] * decay_rate
    return adstocked_series

# Placeholder for apply_saturation function - Will be updated in the next cell
def apply_saturation(data_series, gamma, kappa):
    """Applies Hill saturation function: x^gamma / (x^gamma + kappa^gamma)"""
    # Ensure data_series is numeric
    if not pd.api.types.is_numeric_dtype(data_series):
        print(f"Warning: Data series is not numeric. Cannot apply saturation.")
        return data_series # Return original or empty series as appropriate

    # Handle potential zero values and division by zero
    data_series = data_series.replace(0, 1e-9) # Replace 0 with a very small number to avoid log(0) or division by zero issues if needed later

    # Standard Hill function form
    return data_series**gamma / (data_series**gamma + kappa**gamma)


# --- Adstock Transformation (Applied to Paid Media - Adstock Only) ---

print("\n" + "="*60)
print("ADSTOCK TRANSFORMATION (PAID MEDIA - ADSTOCK ONLY)")
print("="*60)

# Use a non-local variable to hold the data and update it
adstock_data = globals()['data'].copy() if 'data' in globals() and globals()['data'] is not None else None
globals()['adstock_data'] = adstock_data # Make this accessible globally for modification by button clicks

output_adstock = widgets.Output()
display(output_adstock)

if adstock_data is None:
    with output_adstock:
        print("No data available. Please run Data Upload and EDA first.")
else:
    # Dynamically identify potential media variables from current DataFrame columns
    # Prioritize engineered media variables (split and super campaign)
    engineered_media_keywords_in_cols = ['_pre_', '_post_', 'super'] # Keywords to identify engineered vars actually *in* the columns
    # Get all numeric columns from the current data state
    all_numeric_cols = adstock_data.select_dtypes(include=[np.number]).columns.tolist()

    # Identify engineered media variables present in the current data
    engineered_media_vars = [col for col in all_numeric_cols if any(keyword in col.lower() for keyword in engineered_media_keywords_in_cols)]

    # Identify original media variables present in the current data
    media_keywords = ['impressions', 'clicks', 'social', 'search', 'email', 'video', 'spend', 'cost', 'budget']
    original_media_vars = [col for col in all_numeric_cols if any(keyword in col.lower() for keyword in media_keywords) and col not in engineered_media_vars]

    # Determine which original media variables should be excluded because an engineered version exists
    # Check if the original variable name (case-insensitive and removing spaces) is part of any engineered variable name
    original_to_exclude = set()
    for orig_var in original_media_vars:
        # Normalize names for comparison (lowercase, remove spaces)
        normalized_orig = orig_var.lower().replace(" ", "")
        if any(normalized_orig in eng_var.lower().replace(" ", "") for eng_var in engineered_media_vars):
             original_to_exclude.add(orig_var)

    # Exclude original media variables that are components of existing super campaign variables
    super_campaign_vars_in_data = [col for col in engineered_media_vars if 'super' in col.lower()]
    component_vars_of_super = set()
    # This part needs refinement to dynamically identify components.
    # For this dataset, assuming 'super media' is composed of 'Modular Video Impressions' and 'Paid Social Impressions'
    # A more general solution would require tracking component variables during super campaign creation.
    if 'super media' in super_campaign_vars_in_data:
        if 'Modular Video Impressions' in original_media_vars:
             component_vars_of_super.add('Modular Video Impressions')
        if 'Paid Social Impressions' in original_media_vars:
             component_vars_of_super.add('Paid Social Impressions')

    # The final list of media variables for adstock consideration:
    # Include all engineered media variables, AND original media variables that do NOT have an engineered counterpart,
    # AND are NOT component variables of existing super campaigns.
    media_vars_for_adstock = sorted(list(engineered_media_vars + [var for var in original_media_vars if var not in original_to_exclude and var not in component_vars_of_super]))


    # Filter to ensure these variables exist in the data, are numeric, and have no missing values
    adstock_vars_no_nan = [
        var for var in media_vars_for_adstock
        if var in adstock_data.columns and adstock_data[var].isnull().sum() == 0 and pd.api.types.is_numeric_dtype(adstock_data[var])
    ]

    if not adstock_vars_no_nan:
        with output_adstock:
             print("No numeric media variables found without missing values for adstock transformation.")
    else:
        # Create FloatText widgets for Half-Life for each potential variable
        hl_widgets = {}
        hl_widgets_list = []
        for var in adstock_vars_no_nan:
            hl_widget = FloatText(
                description=f'HL for {var}:',
                value=0.0, # Default to 0.0, indicating no adstock applied initially
                disabled=False,
                layout=widgets.Layout(width='500px') # Adjust width for readability
            )
            hl_widgets[var] = hl_widget
            hl_widgets_list.append(hl_widget)


        apply_adstock_button = Button(description='Apply Adstock', button_style='success')
        undo_adstock_button = Button(description="Undo Adstock", button_style='warning')
        adstock_output_area = Output() # Specific output for adstock process

        # Display widgets
        with output_adstock:
            print("\n--- Adstock Transformation Setup ---")
            print("Enter a Half-Life value (periods, e.g., 8) for variables you want to adstock. Leave as 0 to skip.")
            display(VBox(hl_widgets_list + [HBox([apply_adstock_button, undo_adstock_button]), adstock_output_area]))
            print("-" * 30)


        # Handle Apply Adstock button click
        def on_apply_adstock_button_clicked(b):
            global adstock_data # Use global to modify the variable outside the function
            with adstock_output_area:
                clear_output(wait=True) # Clear previous adstock output

                media_half_lives = {} # Dictionary to store HL for plotting later
                adstocked_vars_created_list = [] # List to track created adstocked vars

                print("\n--- Applying Adstock Transformation ---")

                # Keep track of variables that were originally in the data before this adstock application
                # This is to avoid dropping valid non-adstocked columns during undo if they weren't adstocked
                original_cols_before_adstock = set(adstock_data.columns)

                # Identify columns to potentially drop (existing adstocked columns)
                existing_adstocked_cols = [col for col in adstock_data.columns if '_adstocked_HL' in col]

                # Create a temporary copy of the data to work with for this application round
                temp_adstock_data = adstock_data.copy()

                # Iterate through the widgets to get the user-provided Half-Life values
                for media_var, hl_widget in hl_widgets.items(): # Iterate through the dictionary items
                    hl = hl_widget.value

                    if hl is not None and hl > 0: # Apply adstock if Half-Life is positive
                        # Calculate Retention Rate (RR)
                        rr = (0.5)**(1/hl)

                        # Create new column name
                        hl_name_part = str(hl).replace('.', '').replace('-', 'minus')
                        adstocked_col_name = f'{media_var}_adstocked_HL{hl_name_part}'

                        # Ensure the media variable exists and is numeric before applying adstock
                        if media_var in temp_adstock_data.columns and pd.api.types.is_numeric_dtype(temp_adstock_data[media_var]):
                             # Apply adstock to the variable in the temporary dataframe
                             temp_adstock_data[adstocked_col_name] = apply_adstock(temp_adstock_data[media_var], rr)
                             media_half_lives[adstocked_col_name] = hl # Store HL for plotting
                             adstocked_vars_created_list.append(adstocked_col_name) # Add to created list
                             print(f"Applied Adstock to '{media_var}' with HL={hl} -> '{adstocked_col_name}'")
                        else:
                             print(f"Warning: Variable '{media_var}' not found or not numeric. Skipping adstock transformation.")

                    else:
                         # If HL is 0 or negative/None, the variable is not adstocked in this step.
                         # Ensure the original variable is kept and any previous adstocked versions are noted for potential dropping.
                         pass # Do nothing if HL is not positive

                # Now, merge the temporary dataframe back into the main adstock_data
                # Drop original adstocked columns from the main dataframe before merging new ones
                cols_to_drop_from_main = [col for col in existing_adstocked_cols if col not in adstocked_vars_created_list]
                if cols_to_drop_from_main:
                     adstock_data = adstock_data.drop(columns=cols_to_drop_from_main)
                     print(f"Dropped old adstocked columns: {cols_to_drop_from_main}")


                # Identify new columns created in this run
                newly_created_cols = [col for col in temp_adstock_data.columns if col not in adstock_data.columns]

                # Add newly created adstocked columns from temp_adstock_data to the main adstock_data
                for new_col in newly_created_cols:
                    adstock_data[new_col] = temp_adstock_data[new_col]


                # Update the global data variable with the modified adstock_data
                globals()['data'] = adstock_data.copy()
                globals()['media_half_lives'] = media_half_lives # Store HL values globally for plotting

                print("\nAdstock Transformation Complete.")
                print("="*60)

                # Explicitly print the head of the data after adstock transformation
                print("\n--- Data Head After Adstock Transformation ---")
                display(adstock_data.head())
                print("-" * 30)

                # Explicitly print the list of adstocked variables created
                adstocked_vars_created = [col for col in adstock_data.columns if '_adstocked_HL' in col]
                globals()['adstocked_media_vars'] = adstocked_vars_created # Update global list

                print("\n--- Adstocked Variables Currently in Data ---")
                print(adstocked_vars_created)
                print("-" * 30)

                # --- Generate Adstock Decay Curves from Newly Created Adstocked Variables ---
                print("\n" + "="*60)
                print("GENERATING ADSTOCK DECAY CURVES")
                print("="*60)

                adstocked_vars_for_plotting = adstocked_vars_created

                if not adstocked_vars_for_plotting:
                    print("No adstocked variables found in the data to plot decay curves.")
                else:
                    print("\nGenerating decay curves for:")
                    for var in adstocked_vars_for_plotting:
                        print(f"- {var}")
                    print("-" * 30)

                    # Fetch the latest half-lives from the global variable
                    latest_media_half_lives = globals().get('media_half_lives', {})

                    for adstocked_var_name in adstocked_vars_for_plotting:
                        # Try to get the HL from the latest dictionary first
                        hl_value = latest_media_half_lives.get(adstocked_var_name)

                        # If not found there, try to extract it from the column name as a fallback
                        if hl_value is None or hl_value <= 0:
                            try:
                                # Extract HL from column name like 'VarName_adstocked_HL80'
                                hl_str_part = adstocked_var_name.split('_adstocked_HL')[1]
                                # Remove any trailing parts (like _saturated_...) and replace 'minus'
                                hl_str = hl_str_part.split('_saturated_')[0].replace('minus', '-')
                                hl_value = float(hl_str)
                                # Store this extracted value in the dictionary for future plots in this run
                                latest_media_half_lives[adstocked_var_name] = hl_value
                                globals()['media_half_lives'] = latest_media_half_lives # Update global
                            except (IndexError, ValueError):
                                print(f"Warning: Could not extract Half-Life from variable name '{adstocked_var_name}'. Cannot plot decay curve.")
                                continue


                        if hl_value is None or hl_value <= 0:
                             print(f"Warning: Could not retrieve or extract a valid Half-Life ({hl_value}) for variable '{adstocked_var_name}'. Cannot plot decay curve.")
                             continue


                        # Calculate the Retention Rate (RR) from the extracted HL
                        rr_for_curve = (0.5)**(1/hl_value)

                        # Generate points for the decay curve
                        periods = np.arange(0, int(hl_value * 2) + 5) # Plot up to roughly 2x HL + a buffer
                        decay_values = [rr_for_curve**p for p in periods] # Effect of an impulse at time 0

                        plt.figure(figsize=(8, 5))
                        plt.plot(periods, decay_values, marker='o', linestyle='-', label='Adstock Decay')

                        # Add reference points
                        if rr_for_curve > 0 and rr_for_curve < 1:
                             estimated_hl_from_rr = hl_value # Use the stored HL directly

                             # Plot 50% effect point if within plot range
                             if estimated_hl_from_rr >= periods.min() and estimated_hl_from_rr <= periods.max():
                                  plt.plot(estimated_hl_from_rr, 0.5, marker='o', color='green', markersize=10, label=f'50% Effect (HL)')
                                  plt.axvline(x=estimated_hl_from_rr, color='green', linestyle='dashed', label=f"HL ({estimated_hl_from_rr:.2f} periods)")

                             # Plot 25% effect point if within plot range (optional)
                             # x_25 = np.log(0.25) / np.log(rr_for_curve)
                             # if x_25 >= periods.min() and x_25 <= periods.max():
                             #      plt.plot(x_25, 0.25, marker='x', color='purple', markersize=10, label=f'25% Effect')
                             #      plt.axvline(x=x_25, color='purple', linestyle='dotted', label=f"~25% Effect ({x_25:.2f} periods)")


                        # Extract original raw name from adstocked variable name for title
                        # Handle cases where variable name might already contain '_adstocked_' from previous runs
                        original_raw_name = adstocked_var_name.split('_adstocked_HL')[0] if '_adstocked_HL' in adstocked_var_name else adstocked_var_name.split('_saturated_')[0]

                        plt.title(f"Adstock Decay Curve for {original_raw_name} (HL={hl_value:.2f}, RR={rr_for_curve:.2%})")
                        plt.xlabel("Periods (Weeks) Since Impulse")
                        plt.ylabel("Decay Factor (Effect Remaining)")
                        plt.ylim(0, 1.1)
                        plt.grid(True)
                        plt.legend()
                        plt.show()

                print("\nAdstock Decay Curve Generation Complete.")
                print("="*60)


        apply_adstock_button.on_click(on_apply_adstock_button_clicked)

        # Handle Undo Adstock button click
        def on_undo_adstock_button_clicked(b):
             global adstock_data # Use global to modify the variable outside the function
             with adstock_output_area:
                 clear_output(wait=True) # Clear previous output within undo output widget

                 if 'data' in globals() and globals()['data'] is not None:
                      # Find all adstocked columns currently in the data
                      adstocked_cols_to_drop = [col for col in adstock_data.columns if '_adstocked_HL' in col]
                      if adstocked_cols_to_drop:
                           adstock_data = adstock_data.drop(columns=adstocked_cols_to_drop)
                           globals()['data'] = adstock_data.copy() # Update global data
                           globals()['adstocked_media_vars'] = [] # Clear the global list of adstocked vars
                           globals()['media_half_lives'] = {} # Clear the global dictionary of HL values
                           print("\nAdstock Transformation reverted. Adstocked columns removed.")
                           print("\n--- Data Head After Undo Adstock ---")
                           display(adstock_data.head())
                           print("-" * 30)
                           # After undo, re-display the setup widgets so the user can apply again
                           on_run_adstock_setup_button_clicked(None) # Simulate click to re-display setup
                      else:
                           print("No adstocked columns found to undo.")
                           # If nothing to undo, just re-display the setup widgets
                           on_run_adstock_setup_button_clicked(None) # Simulate click to re-display setup


                 else:
                      print("Data before Adstock not found. Cannot undo.")
                      # If data is not available, re-display the initial message
                      on_run_adstock_setup_button_clicked(None) # Simulate click to re-display setup



        # --- Adstock Transformation Setup (Initial Display) ---
        # This function is called once when the cell is executed
        # and again after Undo to reset the display
        def on_run_adstock_setup_button_clicked(b):
            with output_adstock:
                 clear_output(wait=True) # Clear initial output before displaying widgets
                 print("\n--- Adstock Transformation Setup ---")
                 print("Enter a Half-Life value (periods, e.g., 8) for variables you want to adstock. Leave as 0 to skip.")
                 # Re-create and display widgets each time setup is run
                 # This ensures the list reflects the current data state (e.g., after undo)
                 hl_widgets_list_rerun = []
                 latest_adstock_vars_no_nan = [
                      var for var in adstock_data.columns
                      if var not in [col for col in adstock_data.columns if '_adstocked_HL' in col] # Exclude existing adstocked
                      and adstock_data[var].isnull().sum() == 0 and pd.api.types.is_numeric_dtype(adstock_data[var])
                      and any(keyword in var.lower() for keyword in media_keywords + engineered_media_keywords_in_cols) # Ensure it's a media variable
                 ]

                 # Include engineered variables that might not have original counterparts
                 current_engineered_vars = [col for col in adstock_data.columns if any(keyword in col.lower() for keyword in engineered_media_keywords_in_cols) and pd.api.types.is_numeric_dtype(adstock_data[col])]
                 latest_adstock_vars_no_nan.extend([v for v in current_engineered_vars if v not in latest_adstock_vars_no_nan])


                 latest_adstock_vars_no_nan = sorted([v for v in latest_adstock_vars_no_nan if v != 'Week_Ending' and v != globals().get('target_var', 'Sales')])


                 # Filter out components of super campaigns if the super campaign variable exists
                 latest_super_campaign_vars = [col for col in adstock_data.columns if 'super' in col.lower() and pd.api.types.is_numeric_dtype(adstock_data[col])]
                 vars_to_exclude_from_selection = set()
                 # Assuming 'super media' is the only super campaign and its components are 'Modular Video Impressions' and 'Paid Social Impressions'
                 if 'super media' in latest_super_campaign_vars:
                      # This is a heuristic - ideally components are tracked during creation
                      if 'Modular Video Impressions' in adstock_data.columns:
                           vars_to_exclude_from_selection.add('Modular Video Impressions')
                      if 'Paid Social Impressions' in adstock_data.columns:
                           vars_to_exclude_from_selection.add('Paid Social Impressions')

                 # Rebuild the list for widgets, excluding components if super campaign exists
                 adstock_vars_for_widgets = [var for var in latest_adstock_vars_no_nan if var not in vars_to_exclude_from_selection]


                 # Re-create hl_widgets based on the current list of variables for widgets
                 hl_widgets.clear() # Clear previous widgets
                 for var in adstock_vars_for_widgets:
                      hl_widget = FloatText(
                         description=f'HL for {var}:',
                         value=globals().get('media_half_lives', {}).get(f'{var}_adstocked_HL', 0.0), # Try to populate with previous value if available
                         disabled=False,
                         layout=widgets.Layout(width='500px')
                     )
                      hl_widgets[var] = hl_widget
                      hl_widgets_list_rerun.append(hl_widget)


                 if not adstock_vars_for_widgets:
                      print("No numeric media variables found without missing values for adstock transformation.")
                 else:
                      display(VBox(hl_widgets_list_rerun + [HBox([apply_adstock_button, undo_adstock_button]), adstock_output_area]))


        # Call the initial setup function when the cell is first executed
        on_run_adstock_setup_button_clicked(None)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display, HTML, clear_output, Image
import ipywidgets as widgets
from ipywidgets import VBox, HBox, Button, Output, FileUpload, Dropdown, Text, SelectMultiple, FloatText, IntText
import os # Import os for file operations

# Helper Functions

def apply_adstock(data_series, decay_rate):
    """Applies geometric adstock transformation."""
    adstocked_series = data_series.copy()
    if not pd.api.types.is_numeric_dtype(adstocked_series):
        return data_series
    adstocked_series = adstocked_series.fillna(0)
    for i in range(1, len(adstocked_series)):
        adstocked_series.iloc[i] = adstocked_series.iloc[i] + adstocked_series.iloc[i-1] * decay_rate
    return adstocked_series

def apply_saturation(data_series, gamma, kappa):
    """Applies Hill saturation function: x^gamma / (x^gamma + kappa^gamma)"""
    if not pd.api.types.is_numeric_dtype(data_series):
        print(f"Warning: Data series is not numeric. Cannot apply saturation.")
        return data_series

    epsilon = 1e-9
    kappa_effective = kappa + epsilon if kappa == 0 else kappa

    gamma = min(gamma, 100)
    data_series_positive = data_series.clip(lower=0)

    return data_series_positive**gamma / (data_series_positive**gamma + kappa_effective**gamma)

def format_number(num):
    """Formats a number for display with appropriate suffixes (K, M, B) or as integer if specified."""
    target_kappa_value = 2080261.732665588
    if abs(num - target_kappa_value) < 1e-9:
        return "2080261"

    if abs(num) >= 1e9:
        return f'{num / 1e9:.2f}B'
    elif abs(num) >= 1e6:
        return f'{num / 1e6:.2f}M'
    elif abs(num) >= 1e3:
        return f'{num / 1e3:.2f}K'
    else:
        return f'{num:.2f}'


# Function to plot saturation curves using Matplotlib
def plot_saturation_curves(saturated_vars_for_plotting, media_gammas_used, media_kappas_used, saturation_data, output_widget):
     with output_widget:
          print("\n" + "="*60)
          print("GENERATING SATURATION CURVES")
          print("="*60)

          if not saturated_vars_for_plotting:
              print("No saturated variables found in the data to plot saturation curves.")
          else:
               print("\nGenerating saturation curves for:")
               for var in saturated_vars_for_plotting:
                   original_adstocked_name = var.split('_saturated_')[0] if '_saturated_' in var else var
                   print(f"- {original_adstocked_name} (saturated)")
               print("-" * 30)


               for saturated_var_name in saturated_vars_for_plotting:
                    print(f"Attempting to plot saturation curve for: {saturated_var_name}")

                    # Ensure adstocked_var_original_name is defined at the start of the loop
                    adstocked_var_original_name = saturated_var_name.split('_saturated_')[0]


                    try:
                         gamma = media_gammas_used.get(saturated_var_name)
                         kappa = media_kappas_used.get(saturated_var_name)

                         print(f"Retrieved gamma: {gamma}, kappa: {kappa} for {saturated_var_name}")


                         if gamma is None or kappa is None or gamma <= 0 or kappa < 0:
                              print(f"Warning: Could not retrieve valid gamma ({gamma}) or kappa ({kappa}) for variable '{saturated_var_name}'. Cannot plot saturation curve.")
                              continue

                         if gamma > 0:
                              kappa_plot = max(kappa, 1e-9)
                              try:
                                   x_at_99_saturation = (0.99 / (1 - 0.99))**(1/gamma) * kappa_plot
                                   if np.isinf(x_at_99_saturation) or x_at_99_saturation > 1e15:
                                        x_at_99_saturation = kappa_plot * 100
                              except OverflowError:
                                   x_at_99_saturation = 5 * kappa_plot + 100
                              except ZeroDivisionError:
                                   x_at_99_saturation = 5 * kappa_plot + 100

                              # Use the now-defined adstocked_var_original_name
                              max_actual_adstocked_value = saturation_data[adstocked_var_original_name].max() if adstocked_var_original_name in saturation_data.columns else x_at_99_saturation * 2
                              max_input_range = min(max(x_at_99_saturation * 1.5, kappa_plot * 5), max_actual_adstocked_value * 2)

                         else: # Handle the case where gamma is not > 0, ensure max_input_range is still defined
                                # Use the now-defined adstocked_var_original_name
                                max_input_range = saturation_data[adstocked_var_original_name].max() * 1.2 if adstocked_var_original_name in saturation_data.columns else 100

                         max_input_range = max(max_input_range, 1.0)

                         input_values_range = np.linspace(0, max_input_range, 200)
                         kappa_plot = max(kappa, 1e-9)
                         saturated_values_range = apply_saturation(pd.Series(input_values_range), gamma, kappa)


                         plt.figure(figsize=(8, 5))
                         plt.plot(input_values_range, saturated_values_range, label='Saturation Curve')

                         if gamma > 0 and kappa >= 0:
                             x_50 = kappa
                             if x_50 >= 0 and x_50 <= max_input_range:
                                  y_50 = apply_saturation(pd.Series([x_50]), gamma, kappa).iloc[0]
                                  plt.plot(x_50, y_50, marker='o', color='green', markersize=10, label='50% Saturation (x=Kappa)')
                                  plt.axvline(x=x_50, color='green', linestyle='dashed', label=f"50% Saturation (Input: {format_number(x_50)})")


                         if gamma > 0 and kappa >= 0:
                              try:
                                   x_80 = (4**(1/gamma)) * kappa
                                   if np.isinf(x_80) or x_80 > 1e15:
                                        x_80 = kappa_plot * 50
                              except OverflowError:
                                   x_80 = kappa_plot * 50


                              if x_80 >= 0 and x_80 <= max_input_range:
                                   y_80 = apply_saturation(pd.Series([x_80]), gamma, kappa).iloc[0]
                                   plt.plot(x_80, y_80, marker='o', color='red', markersize=10, label='80% Saturation')
                                   plt.axvline(x=x_80, color='red', linestyle='dashed', label=f"80% Saturation (Input: {format_number(x_80)})")


                         parts = saturated_var_name.split('_adstocked_HL')
                         original_raw_name = parts[0] if parts else saturated_var_name.split('_saturated_')[0]

                         plt.title(f"Saturation Curve for {original_raw_name} (Gamma={gamma}, Kappa={kappa})")
                         plt.xlabel("Adstocked Input Value")
                         plt.ylabel("Saturated Output Value")
                         plt.ylim(0, 1.1)
                         plt.grid(True)
                         plt.legend()
                         plt.show()


                         print(f"Successfully generated plot for: {saturated_var_name}")
                         print("-" * 30)

                    except Exception as e:
                         print(f"Error generating plot for {saturated_var_name}: {e}")
                         print("-" * 30)


# --- Apply Saturation (Hill Function) and Plot Saturation Curves ---

print("\n" + "="*60)
print("APPLYING SATURATION & PLOTTING SATURATION CURVES")
print("="*60)

if 'adstocked_media_vars' not in globals() or not globals()['adstocked_media_vars']:
    print("No adstocked variables found from the previous Adstock Transformation step.")
    print("Saturation transformation and plotting skipped.")
    globals()['saturated_media_vars_created'] = []
    globals()['media_gammas_used'] = {}
    globals()['media_kappas_used'] = {}
    globals()['final_media_vars'] = []
else:
    globals()['saturated_media_vars_created'] = []
    globals()['media_gammas_used'] = {}
    globals()['media_kappas_used'] = {}

    saturation_data = globals()['data'].copy() if 'data' in globals() and globals()['data'] is not None else None
    globals()['saturation_data'] = saturation_data

    output_saturation = widgets.Output()
    display(output_saturation)

    if saturation_data is None:
         with output_saturation:
              print("No data available. Please run Data Upload, EDA, Feature Engineering, Adstock, and Saturation steps first.")
    else:
        adstocked_vars_for_saturation = [var for var in globals()['adstocked_media_vars'] if var in saturation_data.columns and pd.api.types.is_numeric_dtype(saturation_data[var])]


        if not adstocked_vars_for_saturation:
            with output_saturation:
                 print("No numeric adstocked variables found in the DataFrame for saturation.")
                 print("Saturation transformation and plotting skipped.")
                 globals()['saturated_media_vars_created'] = []
                 globals()['media_gammas_used'] = {}
                 globals()['media_kappas_used'] = {}


        else:
            with output_saturation:
                print("\nFound the following adstocked variables for saturation:")
                for var in adstocked_vars_for_saturation:
                    print(f"- {var}")
                print("-" * 30)

                gamma_widgets = {}
                kappa_widgets = {}
                gamma_kappa_widgets_list = []

                for var in adstocked_vars_for_saturation:
                    channel_name = var.split('_adstocked_')[0]

                    default_gamma = 1.0
                    if any(x in channel_name.lower() for x in ['search', 'click', 'direct']):
                        default_gamma = 3.0
                    elif any(x in channel_name.lower() for x in ['social', 'email', 'digital']):
                        default_gamma = 1.5
                    elif any(x in channel_name.lower() for x in ['video', 'tv', 'brand', 'display']):
                        default_gamma = 0.7

                    # Set the specified default kappa value
                    default_kappa = 2080261.732665588


                    gamma_widgets[var] = FloatText(
                        description=f'Gamma for {var}:',
                        value=default_gamma,
                        disabled=False,
                        layout=widgets.Layout(width='300px')
                    )
                    kappa_widgets[var] = FloatText(
                         description=f'Kappa for {var}:',
                         value=default_kappa,
                         disabled=False,
                         layout=widgets.Layout(width='300px')
                     )
                    gamma_kappa_widgets_list.append(HBox([gamma_widgets[var], kappa_widgets[var]]))


                apply_saturation_button = Button(description='Apply Saturation & Plot', button_style='success')
                undo_saturation_button = Button(description="Undo Saturation", button_style='warning')
                saturation_output_area = Output()

                with output_saturation:
                    print("\n--- Saturation Transformation Setup ---")
                    print("Enter Gamma and Kappa values for variables you want to saturate. Leave default values to use guidance or modify as needed.")
                    print("\nGuidance for gamma values:")
                    print("- High gamma (2.0-5.0): C-Shaped curve - Good for direct response channels")
                    print("- Medium gamma (1.0-2.0): Moderate S-Shape - Good for social/short-consideration")
                    print("- Low gamma (0.1-1.0): S-Shaped curve - Good for brand building channels")
                    print("\nGuidance for kappa values:")
                    print("- Kappa influences the inflection point of the curve.")
                    print("- A good starting point for kappa is the average value of the adstocked variable.")
                    print("-" * 40)
                    print("Click 'Apply Saturation & Plot' to generate the saturated variables and view the plots.")
                    print("Plots will be generated using Matplotlib (non-interactive).") # Clarified using Matplotlib

                    display(VBox(gamma_kappa_widgets_list + [HBox([apply_saturation_button, undo_saturation_button]), saturation_output_area]))
                    print("-" * 30)


            def on_apply_saturation_button_clicked(b):
                global saturation_data
                with saturation_output_area:
                    clear_output(wait=True)

                    media_gammas_used = {}
                    media_kappas_used = {}
                    saturated_media_vars_created_local = []

                    print("\n--- Applying Saturation Transformation ---")

                    for adstocked_var in adstocked_vars_for_saturation:
                        gamma = gamma_widgets[adstocked_var].value
                        kappa = kappa_widgets[adstocked_var].value

                        if gamma is not None and gamma > 0 and kappa is not None and kappa >= 0:
                            gamma_name_part = str(gamma).replace('.', '').replace('-', 'minus')
                            kappa_name_part = str(kappa).replace('.', '').replace('-', 'minus')
                            saturated_col_name = f'{adstocked_var}_saturated_gamma{gamma_name_part}_kappa{kappa_name_part}'

                            if adstocked_var in saturation_data.columns and pd.api.types.is_numeric_dtype(saturation_data[adstocked_var]):
                                 if saturated_col_name in saturation_data.columns:
                                      saturation_data = saturation_data.drop(columns=[saturated_col_name])

                                 saturation_data[saturated_col_name] = apply_saturation(saturation_data[adstocked_var], gamma, kappa)
                                 saturated_media_vars_created_local.append(saturated_col_name)
                                 media_gammas_used[saturated_col_name] = gamma
                                 media_kappas_used[saturated_col_name] = kappa
                                 print(f"Applied Saturation to '{adstocked_var}' with gamma={gamma}, kappa={kappa} -> '{saturated_col_name}'")

                            else:
                                 print(f"Warning: Adstocked variable '{adstocked_var}' not found or not numeric. Skipping saturation transformation.")

                        else:
                             pass

                    globals()['data'] = saturation_data.copy()
                    globals()['saturated_media_vars_created'] = saturated_media_vars_created_local
                    globals()['media_gammas_used'] = media_gammas_used
                    globals()['media_kappas_used'] = media_kappas_used

                    print("\nSaturation Transformation Complete.")
                    print("="*60)

                    print("\n--- Data Head After Saturation Transformation ---")
                    display(saturation_data.head())
                    print("-" * 30)

                    print("\n--- Saturated Variables Created ---")
                    display_names = [f"{var.split('_adstocked_')[0] if '_adstocked_' in var else var} (saturated)" for var in saturated_media_vars_created_local]
                    print(display_names)
                    print("-" * 30)

                    plot_saturation_curves(saturated_media_vars_created_local, media_gammas_used, media_kappas_used, saturation_data, saturation_output_area)


                    print("\n--- Next Step: Prepare Data for Modeling ---")
                    print("Please run the next cell to prepare the data and select variables for the modeling process.")


            apply_saturation_button.on_click(on_apply_saturation_button_clicked)

            def on_undo_saturation_button_clicked(b):
                 global saturation_data
                 with saturation_output_area:
                     clear_output(wait=True)

                     if 'data' in globals() and globals()['data'] is not None:
                          saturated_cols_to_drop = [col for col in saturation_data.columns if '_saturated_gamma' in col and '_kappa' in col]
                          if saturated_cols_to_drop:
                               saturation_data = saturation_data.drop(columns=saturated_cols_to_drop)
                               globals()['data'] = saturation_data.copy()
                               globals()['saturated_media_vars_created'] = []
                               globals()['media_gammas_used'] = {}
                               globals()['media_kappas_used'] = {}
                               print("\nSaturation Transformation reverted. Saturated columns removed.")
                               print("\n--- Data Head After Undo Saturation ---")
                               display(saturation_data.head())
                               print("-" * 30)
                          else:
                               print("No saturated columns found to undo.")

                     else:
                          print("Data before Saturation not found. Cannot undo.")


            undo_saturation_button.on_click(on_undo_saturation_button_clicked)